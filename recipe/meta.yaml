{% set version = "2.6.1" %}

package:
  name: category_encoders
  version: {{ version }}

source:
  - url: https://pypi.io/packages/source/c/category_encoders/category_encoders-{{ version }}.tar.gz
    sha256: 59eba46127c2ce4cd31e0177e0a55792090b7b2a0e6f50517a27e1f2251d7622
    folder: dist
  - url: https://github.com/scikit-learn-contrib/category_encoders/archive/{{ version }}.tar.gz
    sha256: 51d4c594cd102a3d30a4a00f3ffa62f73b3d2f4298e7a57df8a8046a8d7881f5
    folder: src

build:
  noarch: python
  number: 0
  script:
    - cd dist && {{ PYTHON }} -m pip install -vvv .

requirements:
  host:
    - pip
    - python >=3.5
  run:
    - numpy >=1.14.0
    - pandas >=1.0.5
    - patsy >=0.5.1
    - python >=3.5
    - scikit-learn >=0.20.0
    - scipy >=1.0.0
    - statsmodels >=0.9.0

test:
  source_files:
    - src/tests
  requires:
    - cython
    - pip
    - pytest
    - pytest-cov
    - setuptools <66
  imports:
    - category_encoders
  commands:
    - pip check
    - pytest src -vv --cov=category_encoders --cov-branch -k="not (pandas_index or truncated_index)" --cov-report=term-missing:skip-covered --no-cov-on-fail --cov-fail-under=89 -p no:warnings

about:
  home: https://github.com/scikit-learn-contrib/category_encoders
  license: BSD-3-Clause
  license_family: BSD
  license_file: dist/LICENSE.md
  summary: A collection of sklearn transformers to encode categorical variables as numeric
  doc_url: https://contrib.scikit-learn.org/category_encoders/
  description: |-
    A set of scikit-learn-style transformers for encoding categorical variables
    into numeric with different techniques. While ordinal, one-hot, and hashing
    encoders have similar equivalents in the existing scikit-learn version, the
    transformers in this library all share a few useful properties:

    - First-class support for pandas dataframes as an input (and optionally as
      output)

    - Can explicitly configure which columns in the data are encoded by name or
      index, or infer non-numeric columns regardless of input type

    - Can drop any columns with very low variance based on training set
      optionally

    - Portability: train a transformer on data, pickle it, reuse it later and
      get the same thing out.

    - Full compatibility with sklearn pipelines, input an array-like dataset
      like any other transformer

extra:
  recipe-maintainers:
    - bollwyvl
    - nirajd
    - wdm0006
